# 量化

## 定义[2]

量化就是将神经网络的浮点算法转换为定点。这样就可以在移动手机上实现网络的实时运算，对云计算的部署也有帮助。

常规精度一般使用 FP32（32位浮点，单精度）存储模型权重；低精度则表示 FP16（半精度浮点），INT8（8位的定点整数）等等数值格式。不过目前低精度往往指代 INT8。

由于 INT8 使用的比特数只有 FP32 的 25% ，所以如果量化方法得当，我们可以得到精度效果好，但是内存占用大大减少的模型。

## 为什么需要量化？

想象一下，一个使用 ATmega328P 微控制器的 Arduino Uno，它使用 8 位运算。要想在 Uno 上运行一个模型，理想情况下模型权重必须存储为 8 位整数（而许多台式计算机和笔记本电脑使用 32 位或 64 位浮点表示）。通过量化模型，权重的存储大小减少为原来的 4 分之一（如 32 位到 8 位值的量化），而对准确度的影响可以忽略（通常约为 1–3%）。



8 位编码过程中量化误差的示意图（图源：https://tinymlbook.com/）

此外，在量化过程中，由于量化误差，一些信息可能会丢失。为了解决这个问题，量化感知（QA）训练被提出并作为一种替代方案。

## TPU[3]

TPU的高性能还来源于对于低运算精度的容忍。研究结果表明，低精度运算带来的算法准确率损失很小，但是在硬件实现上却可以带来巨大的便利，包括功耗更低、速度更快、占芯片面积更小的运算单元、更小的内存带宽需求等。TPU采用了8比特的低精度运算。

[1]: https://www.jiqizhixin.com/articles/2020-11-02-7
[2]: https://blog.csdn.net/Rocky6688/article/details/107954339as
[3]: https://blog.csdn.net/Rocky6688/article/details/107252916
