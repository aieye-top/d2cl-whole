{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electronic-cologne",
   "metadata": {},
   "source": [
    "# save_load\n",
    "\n",
    "在训练完成之前，我们需要每隔一段时间保存模型当前参数值，一方面可以防止断电重跑，另一方面可以观察不同迭代次数模型的表现；在训练完成以后，我们需要保存模型参数值用于后续的测试过程。所以，保存的对象包含网络参数值、优化器参数值、epoch值等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-maldives",
   "metadata": {},
   "source": [
    "```py\n",
    "model.load_state_dict(torch.load(\"models/net.pth\"))\n",
    "print(model.state_dict())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-timeline",
   "metadata": {},
   "source": [
    "pytorch中state_dict()和load_state_dict()函数配合使用可以实现状态的获取与重载，load()和save()函数配合使用可以实现参数的存储与读取。\n",
    "\n",
    "## wandb\n",
    "\n",
    "wandb，weights&bias，最近发现的一个神库。\n",
    "\n",
    "深度学习实验结果保存与分析是最让我头疼的一件事情，每个实验要保存对应的log，training curve还有生成图片等等，光这些visualization就需要写很多重复的代码。跨设备的话还得把之前实验的记录都给拷到新设备去。\n",
    "\n",
    "https://github.com/wandb/client\n",
    "\n",
    "[1]: 一文梳理pytorch保存和重载模型参数攻略 - 机器学习入坑者的文章 - 知乎 https://zhuanlan.zhihu.com/p/94971100\n",
    "[2]: 有没有什么可以节省大量时间的 Deep Learning 效率神器？ - Fing的回答 - 知乎 https://www.zhihu.com/question/384519338/answer/1160886439"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}