{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    " * @version:\n",
    " * @Author:  StevenJokess https://github.com/StevenJokess\n",
    " * @Date: 2020-10-16 20:56:49\n",
    " * @LastEditors:  StevenJokess https://github.com/StevenJokess\n",
    " * @LastEditTime: 2020-12-30 20:41:26\n",
    " * @Description:\n",
    " * @TODO::\n",
    " * @Reference:https://ai.deepshare.net/detail/v_5ee644a796c35_tAwVkVvK/3?from=p_5ee641d2e8471_5z8XYfL6&type=6\n",
    " * https://ai.deepshare.net/detail/v_5ee644d9ed5d3_17ThW2c9/3?from=p_5ee641d2e8471_5z8XYfL6&type=6\n",
    " * https://ai.deepshare.net/detail/v_5ee645075753a_qSt7UuAU/3?from=p_5ee641d2e8471_5z8XYfL6&type=6\n",
    " * [5]: https://paddleclas.readthedocs.io/zh_CN/latest/models/Mobile.html\n",
    " * [6]: https://github.com/shicai/MobileNet-Caffe\n",
    " * [7]: https://www.zhihu.com/question/58941804\n",
    "-->\n",
    "\n",
    "# MobileNet\n",
    "\n",
    "该网络将传统的卷积操作替换深度可分离卷积，即Depthwise卷积和Pointwise卷积的组合，相比传统的卷积操作，该组合可以大大节省参数量和计算量。与此同时，MobileNetV1也可以用于目标检测、图像分割等其他视觉任务中。[5]\n",
    "\n",
    "MobileNet is a stack of the separable convolution modules which are composed of depthwise conv and conv1x1 (pointwise conv).\n",
    "Image for post\n",
    "The separable conv independently performs convolution in spatial and channel domains. This factorization of convolution significantly reduces the computational cost from HWNK²M to HWNK² (depthwise) + HWNM (conv1x1), HWN(K² + M) in total. In general, M>>K² (e.g. K=3 and M ≥ 32), the reduction rate is roughly 1/8–1/9.\n",
    "The important point here is that the bottleneck of the computational cost is now conv1x1![8]\n",
    "\n",
    "## ResNet\n",
    "\n",
    "## Activation\n",
    "\n",
    "## 轻量化网络的客观需求\n",
    "\n",
    "小、速度\n",
    "\n",
    "## 本文方法\n",
    "\n",
    "根据应用需求与资源限制（延迟，大小）\n",
    "优化延迟\n",
    "深度可分离卷积 设置两个超参数：balance准确率与延迟\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 结构\n",
    "\n",
    "通过步长来降采样\n",
    "(n+2p-f)/s + 1* (n+2p-f)/s + 1\n",
    "尺度维度变化\n",
    "\n",
    "## 深度可分离卷积\n",
    "\n",
    "深度卷积负责各个通道\n",
    "点卷积1*1*M，每个卷积一个像素\n",
    "\n",
    "\n",
    "\n",
    "深度可分离卷积 分为 深度卷积和 点卷积\n",
    "\n",
    "\n",
    "\n",
    "TODO:https://ai.deepshare.net/detail/v_5ee645312d94a_eMNJ5Jws/3?from=p_5ee641d2e8471_5z8XYfL6&type=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# [3]\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_dw(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "        nn.BatchNorm2d(inp),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, n_class,  profile='normal'):\n",
    "        super(MobileNet, self).__init__()\n",
    "\n",
    "        # original\n",
    "        if profile == 'normal':\n",
    "            in_planes = 32\n",
    "            cfg = [64, (128, 2), 128, (256, 2), 256, (512, 2), 512, 512, 512, 512, 512, (1024, 2), 1024]\n",
    "        # 0.5 AMC\n",
    "        elif profile == '0.5flops':\n",
    "            in_planes = 24\n",
    "            cfg = [48, (96, 2), 80, (192, 2), 200, (328, 2), 352, 368, 360, 328, 400, (736, 2), 752]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.conv1 = conv_bn(3, in_planes, stride=2)\n",
    "\n",
    "        self.features = self._make_layers(in_planes, cfg, conv_dw)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cfg[-1], n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)  # global average pooling\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layers(self, in_planes, cfg, layer):\n",
    "        layers = []\n",
    "        for x in cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(layer(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "[4]\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "#[5]\n",
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "(PROTOTYPE) CONVERT MOBILENETV2 TO NNAPI\n",
    "https://pytorch.org/tutorials/prototype/nnapi_mobilenetv2.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "這邊把各個Block多用一層Sequential包起來是因為Network Pruning的時候抓Layer比較方便。\n",
    "\n",
    "import torchvision.models.quantization.mobilenet\n",
    "\n",
    "\n",
    "MobileNetV1[6]\n",
    "The first version of the MobileNet architecture pioneered the use of depthwise convolutions to make a model more suitable for mobile devices. MobileNetV1 consists almost entirely of 1×1 convolutions and depthwise 3×3 convolutions. We converted the quantized MobileNetV1 model from TensorFlow Lite and benchmarked it on 32-bit ARM builds of TensorFlow Lite and QNNPACK. With both runtimes using 4 threads, we observed 1.8x geomean speedup of QNNPACK over the TensorFlow Lite runtime.\n",
    "\n",
    "深度可分离卷积（Depthwise separable convolution）代替标准的卷积，并使用宽度因子(width multiply)减少参数量。深度可分离卷积把标准的卷积因式分解成一个深度卷积(depthwise convolution)和一个逐点卷积(pointwise convolution)。[7]\n",
    "\n",
    "\n",
    "[1]: https://arxiv.org/abs/1704.04861 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\n",
    "[2]: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\n",
    "[3]: https://github.com/mit-han-lab/amc/blob/master/models/mobilenet.py\n",
    "[4]: https://github.com/mit-han-lab/amc/blob/master/models/mobilenet_v2.py\n",
    "[5]: https://pytorch.org/hub/pytorch_vision_mobilenet_v2/s\n",
    "[6]: https://engineering.fb.com/2018/10/29/ml-applications/qnnpack/\n",
    "[7]: https://cygao.xyz/2019/07/12/lightweight/\n",
    "[8]: https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d\n",
    "\n",
    "https://github.com/0809zheng/Hung-yi-Lee-ML2020-homework/blob/master/hw7_Network_Compression/hw7_Architecture_Design.ipynb"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}