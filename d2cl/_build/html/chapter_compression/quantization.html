<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>3.4. 量化 &#8212; Dive into cheap deep learning 0.0.2 documentation</title>

    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="mix.html" />
    <link rel="prev" title="3.3. Knowledge-Distillation" href="Knowledge-Distillation.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">3. </span>Compression</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">3.4. </span>量化</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_compression/quantization.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://aieye-top.github.io/d2cl/d2cl.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PDF
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/aieye-top/d2cl">
                  <i class="fab fa-github"></i>
                  Github
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Dive into cheap deep learning
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/time.html">1.1. time</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/technology.html">1.2. 技术</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/privacy.html">1.3. 隐私</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/money.html">1.4. money</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/data.html">1.5. Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_lightweight/index.html">2. Lightweight</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/lightweight.html">2.1. Lightweight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/squeezenet.html">2.2. SqueezeNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/mobilenet.html">2.3. MobileNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/mobilenet_v2.html">2.4. MobileNet-v2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/shufflenet.html">2.5. ShuffleNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/GhostNet.html">2.6. GhostNet</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">3. Compression</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="compression.html">3.1. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="pruning.html">3.2. 参数剪枝(Pruning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="Knowledge-Distillation.html">3.3. Knowledge-Distillation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3.4. 量化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_write_code/index.html">4. Write code</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_write_code/jupyter.html">4.1. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_write_code/API.html">4.2. API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_train/index.html">5. Train</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/Server.html">5.1. Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/Active_Learning.html">5.2. Active Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/pretrain.html">5.3. Pretrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/improve.html">5.4. 改进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/structure.html">5.5. 结构</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_deploy/index.html">6. Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/hardware.html">6.1. 芯片</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/edge.html">6.2. Edge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/mobile.html">6.3. mobile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/MCU.html">6.4. MCU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/AI-zhongtai.html">6.5. AI 中台</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Dive into cheap deep learning
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/time.html">1.1. time</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/technology.html">1.2. 技术</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/privacy.html">1.3. 隐私</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/money.html">1.4. money</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/data.html">1.5. Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_lightweight/index.html">2. Lightweight</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/lightweight.html">2.1. Lightweight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/squeezenet.html">2.2. SqueezeNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/mobilenet.html">2.3. MobileNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/mobilenet_v2.html">2.4. MobileNet-v2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/shufflenet.html">2.5. ShuffleNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_lightweight/GhostNet.html">2.6. GhostNet</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">3. Compression</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="compression.html">3.1. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="pruning.html">3.2. 参数剪枝(Pruning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="Knowledge-Distillation.html">3.3. Knowledge-Distillation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3.4. 量化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_write_code/index.html">4. Write code</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_write_code/jupyter.html">4.1. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_write_code/API.html">4.2. API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_train/index.html">5. Train</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/Server.html">5.1. Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/Active_Learning.html">5.2. Active Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/pretrain.html">5.3. Pretrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/improve.html">5.4. 改进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_train/structure.html">5.5. 结构</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_deploy/index.html">6. Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/hardware.html">6.1. 芯片</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/edge.html">6.2. Edge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/mobile.html">6.3. mobile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/MCU.html">6.4. MCU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_deploy/AI-zhongtai.html">6.5. AI 中台</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="id1">
<h1><span class="section-number">3.4. </span>量化<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">3.4.1. </span>性能瓶颈<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>对目前大多数深度学习任务而言，只要过了某个合理的阈值不够成性能瓶颈就行。<a class="reference external" href="http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/">7</a></p>
</div>
<div class="section" id="id3">
<h2><span class="section-number">3.4.2. </span>定义<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>参数量化是指用较低位宽表示典型的32位浮点网络参数,网络参数包括权重、激活值、梯度和误差等等,可以使用统一的位宽(如16-bit、8-bit、2-bit和1-bit等),也可以根据经验或一定策略自由组合不同的位宽.</p>
<div class="section" id="id4">
<h3><span class="section-number">3.4.2.1. </span>优点<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>能够显著减少参数存储空间与内存占用空间,将参数从32位浮点型量化到8位整型,从而缩小75%的存储空间,这对于计算资源有限的边缘设备和嵌入式设备进行深度学习模型的部署和使用都有很大的帮助;</p></li>
<li><p>能够加快运算速度,降低设备能耗,读取32位浮点数所需的带宽可以同时读入4个8位整数,并且整型运算相比浮点型运算更快,自然能够降低设备功耗.但其仍存在一定的局限性,网络参数的位宽减少损失了一部分信息量,会造成推理精度的下降,虽然能够通过微调恢复部分精确度,但也带来时间成本的增加;量化到特殊位宽时,很多现有的训练方法和硬件平台不再适用,需要设计专用的系统架构,灵活性不高.</p></li>
</ol>
<p>量化就是将神经网络的浮点算法转换为定点。这样就可以在移动手机上实现网络的实时运算，对云计算的部署也有帮助。<a class="reference external" href="https://blog.csdn.net/Rocky6688/article/details/107954339as">2</a></p>
<p>常规精度一般使用 FP32（32位浮点，单精度）存储模型权重；低精度则表示
FP16（半精度浮点），INT8（8位的定点整数）等等数值格式。不过目前低精度往往指代
INT8。</p>
</div>
</div>
<div class="section" id="id5">
<h2><span class="section-number">3.4.3. </span>为什么需要量化？<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>想象一下，一个使用 ATmega328P 微控制器的 Arduino Uno，它使用 8
位运算。要想在 Uno 上运行一个模型，理想情况下模型权重必须存储为 8
位整数（而许多台式计算机和笔记本电脑使用 32 位或 64
位浮点表示）。通过量化模型，权重的存储大小减少为原来的 4 分之一（如 32
位到 8 位值的量化），而对准确度的影响可以忽略（通常约为 1–3%）。</p>
<p>8 位编码过程中量化误差的示意图（图源：<a class="reference external" href="https://tinymlbook.com/">https://tinymlbook.com/</a>）</p>
<p>此外，在量化过程中，由于量化误差，一些信息可能会丢失。为了解决这个问题，量化感知（QA）训练被提出并作为一种替代方案。</p>
</div>
<div class="section" id="id6">
<h2><span class="section-number">3.4.4. </span>技术<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>首先考虑简单情况，将浮点数</p>
<div class="math notranslate nohighlight" id="equation-chapter-compression-quantization-0">
<span class="eqno">(3.4.1)<a class="headerlink" href="#equation-chapter-compression-quantization-0" title="Permalink to this equation">¶</a></span>\[x_{\text {float }} \in\left(x_{\min }, x_{\max }\right)\]</div>
<p>量化为整数</p>
<div class="math notranslate nohighlight" id="equation-chapter-compression-quantization-1">
<span class="eqno">(3.4.2)<a class="headerlink" href="#equation-chapter-compression-quantization-1" title="Permalink to this equation">¶</a></span>\[q_{i n t} \in\left(q_{\min }, q_{\max }\right)\]</div>
<p>量化的计算公式为</p>
<div class="math notranslate nohighlight" id="equation-chapter-compression-quantization-2">
<span class="eqno">(3.4.3)<a class="headerlink" href="#equation-chapter-compression-quantization-2" title="Permalink to this equation">¶</a></span>\[q_{\text {int }}=\text { round }\left(\frac{x_{\text {float }}}{\text { scale }}\right)+z p\]</div>
<p>这里需要提前确定量化信息scale、zp。</p>
<p>通常情况下，有以下三种方式来基于浮点数和整数的映射关系进行量化信息的计算，如图2所示。<a class="reference external" href="https://cloud.tencent.com/developer/article/1657774">4</a></p>
<ul class="simple">
<li><p>非饱和方式：将浮点数正负绝对值的最大值对应映射到整数的最大最小值。</p></li>
<li><p>饱和方式：先计算浮点数的阈值，然后将浮点数的正负阈值对应映射到整数的最大最小值。</p></li>
<li><p>仿射方式：将浮点数的最大最小值对应映射到整数的最大最小值。</p></li>
</ul>
<p>模型量化是对原始模型中的权重和激活进行量化，量化方法分为以下三种。<a class="reference external" href="https://cloud.tencent.com/developer/article/1657774">4</a></p>
<p>动态离线量化：此方式不需要样本数据。采用非饱和方式进行权重的量化。
静态离线量化：此方式只需使用少量的样本数据进行模型的前向计算，对激活进行数值采样。使用饱和方式量化权重，非饱和方式量化激活。
量化训练：此方式需要使用大量有标签样本数据。通过非饱和方式进行权重和激活的量化，并在训练过程中更新权重。</p>
<p>在权重量化层面,Gupta 发现,使用 16 位的定点数作为权重,足够在 MNIST
上训练一个神经网络 .此外,Dettmers 研究了 8
位定点量化,加快并行训练中深度网络的收敛速度.Han
等人提出了结合权重剪枝,量化和霍夫编码的策略,
可以得到非常高的压缩比,但是这种方法需要专门的运算策略来实现.提出了二值权重网络(Binary
Weight Network, BWN)即对于网络的权重而言,只有 1 或-1 两个值.BWN
采用了一种混合策略(BinaryConnect)对于网络的中间层特征,保留其原始精度,只将网络权重进行二值化,将网络前向传播与反向传播时的乘法操作变为加法操作.在网络的训练过程中,二值化的权重应用于前向传播与反向传播的梯度计算,而在更新权重时,采用全精度的权重,当全精度的权重越过阈值时,其对应的二值化后的权重就会发生改变.在测试时,只保留和使用二值化之后的权重,每个权重只占用一个
bit 的空间,对于 32 位或者 64 位 bit 的浮点数,有 32~64
倍的压缩倍率,并且由于用累加代替了乘法运算,使得网络的运行效率也大幅提升.<a class="reference external" href="https://www.codenong.com/cs108925647/">6</a></p>
</div>
<div class="section" id="id7">
<h2><span class="section-number">3.4.5. </span>工业界<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>工业界最终选择了 INT8 量化—— FP32 在推理（inference）期间被 INT8
取代，而训练（training）仍然是
FP32。TensorRT，TensorFlow，PyTorch，MxNet
和许多其他深度学习软件都已启用（或正在启用）量化。<a class="reference external" href="https://jackwish.net/2019/neural-network-quantization-introduction-chn.html">5</a></p>
<p>一些框架简单地引入了 Quantize 和 Dequantize
层，当从卷积或全链接层送入或取出时，它将 FP32 转换为 INT8
或相反。在这种情况下，如图四的上半部分所示，模型本身和输入/输出采用 FP32
格式。深度学习框架加载模型，重写网络以插入Quantize 和 Dequantize
层，并将权重转换为 INT8
格式。<a class="reference external" href="https://jackwish.net/2019/neural-network-quantization-introduction-chn.html">5</a></p>
</div>
<div class="section" id="tpu3">
<h2><span class="section-number">3.4.6. </span>TPU<a class="reference external" href="https://blog.csdn.net/Rocky6688/article/details/107252916">3</a><a class="headerlink" href="#tpu3" title="Permalink to this headline">¶</a></h2>
<p>TPU的高性能还来源于对于低运算精度的容忍。研究结果表明，低精度运算带来的算法准确率损失很小，但是在硬件实现上却可以带来巨大的便利，包括功耗更低、速度更快、占芯片面积更小的运算单元、更小的内存带宽需求等。TPU采用了8比特的低精度运算。</p>
</div>
<div class="section" id="more">
<h2><span class="section-number">3.4.7. </span>More<a class="headerlink" href="#more" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://jackwish.net/2019/neural-network-quantization-resources.html">https://jackwish.net/2019/neural-network-quantization-resources.html</a></p>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">3.4. 量化</a><ul>
<li><a class="reference internal" href="#id2">3.4.1. 性能瓶颈</a></li>
<li><a class="reference internal" href="#id3">3.4.2. 定义</a><ul>
<li><a class="reference internal" href="#id4">3.4.2.1. 优点</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id5">3.4.3. 为什么需要量化？</a></li>
<li><a class="reference internal" href="#id6">3.4.4. 技术</a></li>
<li><a class="reference internal" href="#id7">3.4.5. 工业界</a></li>
<li><a class="reference internal" href="#tpu3">3.4.6. TPU3</a></li>
<li><a class="reference internal" href="#more">3.4.7. More</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="Knowledge-Distillation.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>3.3. Knowledge-Distillation</div>
         </div>
     </a>
     <a id="button-next" href="mix.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div><no title></div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>