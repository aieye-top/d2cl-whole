{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fundamental-funds",
   "metadata": {},
   "source": [
    "# 充分运用资源\n",
    "\n",
    "通过Nvidia-Dali模块的合理配置，可以显著提升数据加载和在线增强阶段的效率，特别是在训练一些轻量化模型时，往往瓶颈不在于GPU的计算速度，而在于CPU等其他部件的负载；\n",
    "通过DistributedDataParallel模块的合理配置，可以实现多卡的负载均衡，不论是显存占用还是GPU利用率，都能够达到平衡，不会有其中1张卡变成效率瓶颈；\n",
    "通过torch.cuda.amp模块的合理配置，可以进一步降低显存占用，从而可以设置更大的batch_size，提高模型收敛速度；\n",
    "torch.cuda.amp模块还可以显著降低网络前向推理时间，从而进一步提高训练效率。[1]\n",
    "\n",
    "[1]: https://my.oschina.net/lylec/blog/4817005"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}